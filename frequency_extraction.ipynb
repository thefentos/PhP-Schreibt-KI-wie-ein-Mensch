{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import requests\n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 imports/HUMAN-TEXTS-1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY      = os.getenv('OPENAI_API_KEY')\n",
    "PERPLEXITY_API_KEY  = os.getenv('PERPLEXITY_API_KEY')\n",
    "ANTHROPIC_API_KEY   = os.getenv('ANTHROPIC_API_KEY')\n",
    "TEST                = os.getenv('TEST')\n",
    "HUMAN_FILE          = os.getenv('HUMAN_FILE')\n",
    "\n",
    "print(TEST, HUMAN_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_client = openai.OpenAI()\n",
    "ant_client = anthropic.Anthropic()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_full_text(tl, filename, marker='\\n--------------------NEW-TEXT------------------\\n'):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(marker.join(tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt4o_request(prompt, system_prompt):\n",
    "    completion = oai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        temperature=1,\n",
    "        max_tokens=1993,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    return str(completion.choices[0].message.content)\n",
    "\n",
    "def gpt35t_request(prompt, system_prompt):\n",
    "    completion = oai_client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format={\n",
    "            \"type\": \"text\"\n",
    "        },\n",
    "        temperature=1,\n",
    "        max_tokens=1993,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    \n",
    "    return str(completion.choices[0].message.content)\n",
    "\n",
    "def perplxty_request(prompt, system_prompt):\n",
    "    url = \"https://api.perplexity.ai/chat/completions\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"llama-3.1-sonar-large-128k-online\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"max_tokens\": 1993,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 1\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "def clde_request(prompt, system_prompt):\n",
    "    message = ant_client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        max_tokens=1993,\n",
    "        temperature=0.5,\n",
    "        system=system_prompt,  # Top-level system parameter\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    return message.content[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt          = []\n",
    "system_prompt   = ''\n",
    "gpt4o_texts     = []\n",
    "gpt35t_texts    = []\n",
    "perplxty_texts  = []\n",
    "clde_texts      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "if int(TEST) == 1:   \n",
    "    with open('imports/TEST-1', 'r') as f:\n",
    "        human_texts = f.read()\n",
    "else:\n",
    "    with open(HUMAN_FILE, 'r') as f:\n",
    "        human_texts = f.read()\n",
    "\n",
    "human_texts = human_texts.split('--------------------NEW-TEXT------------------')\n",
    "\n",
    "for i in human_texts:\n",
    "    human_txt_list = i.split()\n",
    "    prompt.append(f'Schreibe einen Fußballartikel zum Thema WM Sieg der deutschen National Mannschaft am 13.07.2014! Achten Sie auf fachliche korrektness und auf die im Systemprompt angegebenen Schemata! Der Text beginnt mit: {human_txt_list[0], human_txt_list[1], human_txt_list[2]}. Folgen Sie diesem Beginn! Der Artikel soll mindestens 700 und maximal 800 Wörter lang sein!')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for i in human_texts:\n",
    "    human_txt_list = i.split()\n",
    "    l.append(f'{human_txt_list[0]}, {human_txt_list[1]}, {human_txt_list[2]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['So, reden, große', 'Die, deutsche, Fußball-Nationalelf', 'Es, ist, vollbracht:', 'Deutschland, ist, Weltmeister!', 'Drei, Minuten, vor', 'Da, ist, der', 'Die, DFB-Elf, gewinnt', 'Weltmeister!, Deutschland, ist', 'Die, DFB-Elf, hat', 'Der, eingewechselte, Mario', 'Geschafft!, Die, Deutsche', 'Rio, de, Janeiro', 'Deutschland, hatte, zunächst', 'Am, 13., Juli', 'Mit, einem, mühevollen', 'Nach, einem, dramatischen', 'Weltmeister!, Zum, ersten', '\"Schlaaaaand!!!\", Hunderttausende, Fußballfans', 'Obschon, der, lange', 'Dieses, Spiel!, Diese']\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 0\n",
      "Perplexity: 1\n",
      "Perplexity: 2\n",
      "Perplexity: 3\n",
      "Perplexity: 4\n",
      "Perplexity: 5\n",
      "Perplexity: 6\n",
      "Perplexity: 7\n",
      "Perplexity: 8\n",
      "Perplexity: 9\n",
      "Perplexity: 10\n",
      "Perplexity: 11\n",
      "Perplexity: 12\n",
      "Perplexity: 13\n",
      "Perplexity: 14\n",
      "Perplexity: 15\n",
      "Perplexity: 16\n",
      "Perplexity: 17\n",
      "Perplexity: 18\n",
      "Perplexity: 19\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "Path('backups').mkdir(parents=True, exist_ok=True)\n",
    "for i in prompt:\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "    \n",
    "    perplxty_texts.append(perplxty_request(i, system_prompt))\n",
    "    open(f'backups/perplexity_{timestamp}_{counter}.txt', 'w').write(perplxty_texts[- 1])\n",
    "    print(f'Perplexity: {counter}')\n",
    "\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4o: 0\n",
      "GPT-3.5-turbo: 0\n",
      "Perplexity: 0\n",
      "CLDE: 0\n",
      "GPT-4o: 1\n",
      "GPT-3.5-turbo: 1\n",
      "Perplexity: 1\n",
      "CLDE: 1\n",
      "GPT-4o: 2\n",
      "GPT-3.5-turbo: 2\n",
      "Perplexity: 2\n",
      "CLDE: 2\n",
      "GPT-4o: 3\n",
      "GPT-3.5-turbo: 3\n",
      "Perplexity: 3\n",
      "CLDE: 3\n",
      "GPT-4o: 4\n",
      "GPT-3.5-turbo: 4\n",
      "Perplexity: 4\n",
      "CLDE: 4\n",
      "GPT-4o: 5\n",
      "GPT-3.5-turbo: 5\n",
      "Perplexity: 5\n",
      "CLDE: 5\n",
      "GPT-4o: 6\n",
      "GPT-3.5-turbo: 6\n",
      "Perplexity: 6\n",
      "CLDE: 6\n",
      "GPT-4o: 7\n",
      "GPT-3.5-turbo: 7\n",
      "Perplexity: 7\n",
      "CLDE: 7\n",
      "GPT-4o: 8\n",
      "GPT-3.5-turbo: 8\n",
      "Perplexity: 8\n",
      "CLDE: 8\n",
      "GPT-4o: 9\n",
      "GPT-3.5-turbo: 9\n",
      "Perplexity: 9\n",
      "CLDE: 9\n",
      "GPT-4o: 10\n",
      "GPT-3.5-turbo: 10\n",
      "Perplexity: 10\n",
      "CLDE: 10\n",
      "GPT-4o: 11\n",
      "GPT-3.5-turbo: 11\n",
      "Perplexity: 11\n",
      "CLDE: 11\n",
      "GPT-4o: 12\n",
      "GPT-3.5-turbo: 12\n",
      "Perplexity: 12\n",
      "CLDE: 12\n",
      "GPT-4o: 13\n",
      "GPT-3.5-turbo: 13\n",
      "Perplexity: 13\n",
      "CLDE: 13\n",
      "GPT-4o: 14\n",
      "GPT-3.5-turbo: 14\n",
      "Perplexity: 14\n",
      "CLDE: 14\n",
      "GPT-4o: 15\n",
      "GPT-3.5-turbo: 15\n",
      "Perplexity: 15\n",
      "CLDE: 15\n",
      "GPT-4o: 16\n",
      "GPT-3.5-turbo: 16\n",
      "Perplexity: 16\n",
      "CLDE: 16\n",
      "GPT-4o: 17\n",
      "GPT-3.5-turbo: 17\n",
      "Perplexity: 17\n",
      "CLDE: 17\n",
      "GPT-4o: 18\n",
      "GPT-3.5-turbo: 18\n",
      "Perplexity: 18\n",
      "CLDE: 18\n",
      "GPT-4o: 19\n",
      "GPT-3.5-turbo: 19\n",
      "Perplexity: 19\n",
      "CLDE: 19\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "Path('imports').mkdir(parents=True, exist_ok=True)\n",
    "Path('backups').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in prompt:\n",
    "    timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "    gpt4o_texts.append(gpt4o_request(i, system_prompt))\n",
    "    print(f'GPT-4o: {counter}')\n",
    "    gpt35t_texts.append(gpt35t_request(i, system_prompt))\n",
    "    print(f'GPT-3.5-turbo: {counter}')\n",
    "    perplxty_texts.append(perplxty_request(i, system_prompt))\n",
    "    print(f'Perplexity: {counter}')\n",
    "    clde_texts.append(clde_request(i, system_prompt))\n",
    "    print(f'CLDE: {counter}')\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(perplxty_texts):\n",
    "    char_list = [*i]\n",
    "    result = []\n",
    "    skip = 0\n",
    "\n",
    "    for j in char_list:\n",
    "        if skip > 0:\n",
    "            skip -= 1\n",
    "            continue\n",
    "\n",
    "        if j == '[':\n",
    "            skip = 2  # Überspringe die nächsten 2 Zeichen\n",
    "        elif j == '*':\n",
    "            skip = 0  # Überspringe das nächste Zeichen\n",
    "        elif j == '#':\n",
    "            skip = 0\n",
    "        else:\n",
    "            result.append(j)\n",
    "\n",
    "    new_text = ''.join(result)\n",
    "    perplxty_texts[idx] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(clde_texts):\n",
    "    char_list = [*i]\n",
    "    result = []\n",
    "    skip = 0\n",
    "\n",
    "    for j in char_list:\n",
    "        if skip > 0:\n",
    "            skip -= 1\n",
    "            continue\n",
    "\n",
    "        if j == '[':\n",
    "            skip = 2  # Überspringe die nächsten 2 Zeichen\n",
    "        elif j == '*':\n",
    "            skip = 0  # Überspringe das nächste Zeichen\n",
    "        elif j == '#':\n",
    "            skip = 0\n",
    "        else:\n",
    "            result.append(j)\n",
    "\n",
    "    new_text = ''.join(result)\n",
    "    clde_texts[idx] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(gpt4o_texts):\n",
    "    char_list = [*i]\n",
    "    result = []\n",
    "    skip = 0\n",
    "\n",
    "    for j in char_list:\n",
    "        if skip > 0:\n",
    "            skip -= 1\n",
    "            continue\n",
    "\n",
    "        if j == '[':\n",
    "            skip = 2  # Überspringe die nächsten 2 Zeichen\n",
    "        elif j == '*':\n",
    "            skip = 0  # Überspringe das nächste Zeichen\n",
    "        elif j == '#':\n",
    "            skip = 0\n",
    "        else:\n",
    "            result.append(j)\n",
    "\n",
    "    new_text = ''.join(result)\n",
    "    gpt4o_texts[idx] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, i in enumerate(gpt35t_texts):\n",
    "    char_list = [*i]\n",
    "    result = []\n",
    "    skip = 0\n",
    "\n",
    "    for j in char_list:\n",
    "        if skip > 0:\n",
    "            skip -= 1\n",
    "            continue\n",
    "\n",
    "        if j == '[':\n",
    "            skip = 2  # Überspringe die nächsten 2 Zeichen\n",
    "        elif j == '*':\n",
    "            skip = 0  # Überspringe das nächste Zeichen\n",
    "        elif j == '#':\n",
    "            skip = 0\n",
    "        else:\n",
    "            result.append(j)\n",
    "\n",
    "    new_text = ''.join(result)\n",
    "    gpt35t_texts[idx] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker = '\\n--------------------NEW-TEXT------------------\\n'\n",
    "\n",
    "perplxty_texts_str = marker.join(perplxty_texts)\n",
    "gpt4o_texts_str = marker.join(gpt4o_texts)\n",
    "gpt35t_texts_str = marker.join(gpt35t_texts)\n",
    "clde_texts_str = marker.join(clde_texts)\n",
    "human_texts_str = marker.join(human_texts)\n",
    "\n",
    "with open('exports/perplexity_full.txt', 'w') as f:\n",
    "    f.write(perplxty_texts_str)\n",
    "\n",
    "with open('exports/gpt4o_full.txt', 'w') as f:\n",
    "    f.write(gpt4o_texts_str)\n",
    "\n",
    "with open('exports/gpt35t_full.txt', 'w') as f:\n",
    "    f.write(gpt35t_texts_str)\n",
    "\n",
    "with open('exports/clde_full.txt', 'w') as f:\n",
    "    f.write(clde_texts_str)\n",
    "\n",
    "with open('exports/human_full.txt', 'w') as f:\n",
    "    f.write(human_texts_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_df    = pd.DataFrame({\"words\": []})\n",
    "gpt35t_df   = pd.DataFrame({\"words\": []})\n",
    "gemni_df    = pd.DataFrame({\"words\": []})\n",
    "perplxty_df = pd.DataFrame({\"words\": []})\n",
    "clde_df     = pd.DataFrame({\"words\": []})\n",
    "human_df    = pd.DataFrame({\"words\": []})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in gpt4o_texts:\n",
    "    txt_lem = nlp(txt)\n",
    "    txt_df  = pd.DataFrame([token.lemma_ for token in txt_lem], columns=['words'])\n",
    "    gpt4o_df = pd.concat([gpt4o_df,txt_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for txt in gpt35t_texts:\n",
    "    txt_lem = nlp(txt)\n",
    "    txt_df  = pd.DataFrame([token.lemma_ for token in txt_lem], columns=['words'])\n",
    "    gpt35t_df = pd.concat([gpt35t_df,txt_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for txt in perplxty_texts:\n",
    "    txt_lem = nlp(txt)\n",
    "    txt_df  = pd.DataFrame([token.lemma_ for token in txt_lem], columns=['words'])\n",
    "    perplxty_df = pd.concat([perplxty_df,txt_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for txt in clde_texts:\n",
    "    txt_lem = nlp(txt)\n",
    "    txt_df  = pd.DataFrame([token.lemma_ for token in txt_lem], columns=['words'])\n",
    "    clde_df = pd.concat([clde_df,txt_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for txt in human_texts:\n",
    "    txt_lem = nlp(txt)\n",
    "    txt_df  = pd.DataFrame([token.lemma_ for token in txt_lem], columns=['words'])\n",
    "    human_df = pd.concat([human_df,txt_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4o_df    = gpt4o_df.value_counts().reset_index()\n",
    "gpt35t_df   = gpt35t_df.value_counts().reset_index()\n",
    "perplxty_df = perplxty_df.value_counts().reset_index()\n",
    "clde_df     = clde_df.value_counts().reset_index()\n",
    "human_df    = human_df.value_counts().reset_index()\n",
    "\n",
    "gpt4o_df.columns    = ['words', 'amount']\n",
    "gpt35t_df.columns   = ['words', 'amount']\n",
    "perplxty_df.columns = ['words', 'amount']\n",
    "clde_df.columns     = ['words', 'amount']\n",
    "human_df.columns    = ['words', 'amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H:%M:%S')\n",
    "Path('exports').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gpt4o_df.to_csv(f'exports/GPT4o-{timestamp}.csv', index=True)\n",
    "gpt35t_df.to_csv(f'exports/GPT35t-{timestamp}.csv', index=True)\n",
    "perplxty_df.to_csv(f'exports/PERPLEXITY-{timestamp}.csv', index=True)\n",
    "clde_df.to_csv(f'exports/CLAUDE-{timestamp}.csv', index=True)\n",
    "human_df.to_csv(f'exports/HUMAN-{timestamp}.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
